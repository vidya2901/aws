{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eastern-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from clustimage import Clustimage\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PImage\n",
    "import io\n",
    "import imagehash\n",
    "from undouble import Undouble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungry-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    # return array of images\n",
    "\n",
    "    imagesList = listdir(path)\n",
    "    loadedImages = []\n",
    "    for image in imagesList:\n",
    "        img = PImage.open(path + image)\n",
    "        loadedImages.append(img)\n",
    "\n",
    "    return loadedImages\n",
    "\n",
    "path = \"/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/image_sample/\"\n",
    "\n",
    "# your images in an array\n",
    "imgs = loadImages(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comfortable-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in imgs:\n",
    "    # you can show every image\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "trying-turkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG\n",
      "RGB\n"
     ]
    }
   ],
   "source": [
    "# prints format of image\n",
    "print(imgs[0].format)\n",
    " \n",
    "# prints mode of image\n",
    "print(imgs[0].mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "selected-trick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x768 at 0x10DE15EB0>\n"
     ]
    }
   ],
   "source": [
    "print(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "studied-protection",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[undouble] >INFO> filepath is set to [/var/folders/k8/853v_n2j4mg1fczdrs9bspsh0000gn/T/clustimage]\n",
      "[undouble] >INFO> filepath is set to [/var/folders/k8/853v_n2j4mg1fczdrs9bspsh0000gn/T/clustimage]\n",
      "[undouble] >INFO> filepath is set to [/var/folders/k8/853v_n2j4mg1fczdrs9bspsh0000gn/T/clustimage]\n",
      "[undouble] >WARNING> Scaling not possible.\n",
      "[undouble] >WARNING> Could not read: [/ds/python/gst_image_analysis/image_sample/002406.jpg]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "cl = Clustimage()\n",
    "\n",
    "# Preprocessing of the first image\n",
    "# 0: cv2.IMREAD_GRAYSCALE\n",
    "# 1: cv2.IMREAD_COLOR\n",
    "img_1 = cl.imread(\"/ds/python/gst_image_analysis/image_sample/\"+listdir(path)[0], dim=(128,128), colorscale=0, flatten=True)\n",
    "\n",
    "# Flattened array\n",
    "print(img_1)\n",
    "# array([ 10,  22,  13, ...,  78,  74, 117], dtype=uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "preceding-indication",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-603fb4a88472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot. Note that reshape is only required in case flatten=True\n",
    "plt.figure()\n",
    "plt.imshow(img_1.reshape(128,128))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2 = cl.imread(\"/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/image_sample/\"+listdir(path)[1], dim=(128,128), colorscale=0, flatten=True)\n",
    "print(img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot. Note that reshape is only required in case flatten=True\n",
    "plt.figure()\n",
    "plt.imshow(img_2.reshape(128,128))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Undouble(method='phash', hash_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.import_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_hash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.group(threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/detection-of-duplicate-images-using-image-hash-functions-4d9c53f04a75\n",
    "#https://towardsdatascience.com/a-step-by-step-guide-for-clustering-images-4b45f9906128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results\n",
    "#Took a sample of 2 images and created a copy of both - total 4 images\n",
    "#2 groups were created - same images grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mineral-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "corrected-ukraine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP Model...\n"
     ]
    }
   ],
   "source": [
    "# Load the OpenAI CLIP Model\n",
    "print('Loading CLIP Model...')\n",
    "model = SentenceTransformer('clip-ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "identical-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 2407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6028ed17036a4cefa194f50e97849165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = \"/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/\"\n",
    "\n",
    "# Next we compute the embeddings\n",
    "# To encode an image, you can use the following code:\n",
    "# from PIL import Image\n",
    "# encoded_image = model.encode(Image.open(filepath))\n",
    "image_names = list(glob.glob(filepath + '*'))\n",
    "print(\"Images:\", len(image_names))\n",
    "encoded_image = model.encode([Image.open(filepath) for filepath in image_names], batch_size=128, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "logical-terrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c9942319e64bc884819bd734e7ab5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath1 = \"/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/image_sample/\"\n",
    "\n",
    "# Next we compute the embeddings\n",
    "# To encode an image, you can use the following code:\n",
    "# from PIL import Image\n",
    "# encoded_image = model.encode(Image.open(filepath))\n",
    "image_names1 = list(glob.glob(filepath1 + '*'))\n",
    "print(\"Images:\", len(image_names1))\n",
    "encoded_image1 = model.encode([Image.open(filepath1) for filepath1 in image_names1], batch_size=128, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "threaded-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we run the clustering algorithm. This function compares images aganist \n",
    "# all other images and returns a list with the pairs that have the highest \n",
    "# cosine similarity score\n",
    "processed_images = util.paraphrase_mining_embeddings(encoded_image)\n",
    "NUM_SIMILAR_IMAGES = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "close-percentage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding duplicate images...\n",
      "\n",
      "Score: 100.000%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002284.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000855.jpg\n"
     ]
    }
   ],
   "source": [
    "print('Finding duplicate images...')\n",
    "# Filter list for duplicates. Results are triplets (score, image_id1, image_id2) and is scorted in decreasing order\n",
    "# A duplicate image will have a score of 1.00\n",
    "duplicates = [image for image in processed_images if image[0] >= 1]\n",
    "\n",
    "# Output the top X duplicate images\n",
    "for score, image_id1, image_id2 in duplicates[0:NUM_SIMILAR_IMAGES]:\n",
    "    print(\"\\nScore: {:.3f}%\".format(score * 100))\n",
    "    print(image_names[image_id1])\n",
    "    print(image_names[image_id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "polish-florida",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding near duplicate images...\n",
      "\n",
      "Score: 97.748%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001501.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001500.jpg\n",
      "\n",
      "Score: 97.610%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001886.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000659.jpg\n",
      "\n",
      "Score: 97.384%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000444.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000405.jpg\n",
      "\n",
      "Score: 97.362%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001703.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001702.jpg\n",
      "\n",
      "Score: 97.340%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002386.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000284.jpg\n",
      "\n",
      "Score: 97.269%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001175.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001226.jpg\n",
      "\n",
      "Score: 97.253%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002383.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000340.jpg\n",
      "\n",
      "Score: 97.247%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001175.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001186.jpg\n",
      "\n",
      "Score: 97.235%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002082.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002251.jpg\n",
      "\n",
      "Score: 97.223%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000306.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002261.jpg\n",
      "\n",
      "Score: 97.199%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000974.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001007.jpg\n",
      "\n",
      "Score: 97.103%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002383.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000311.jpg\n",
      "\n",
      "Score: 97.096%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000261.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000262.jpg\n",
      "\n",
      "Score: 97.094%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002035.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002311.jpg\n",
      "\n",
      "Score: 97.089%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000854.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002398.jpg\n",
      "\n",
      "Score: 97.066%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000324.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/002402.jpg\n",
      "\n",
      "Score: 97.058%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001462.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000549.jpg\n",
      "\n",
      "Score: 97.055%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000454.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000444.jpg\n",
      "\n",
      "Score: 97.052%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001662.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/001680.jpg\n",
      "\n",
      "Score: 97.035%\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000335.jpg\n",
      "/Users/vidyakumar/Desktop/ds/python/gst_image_analysis/images/000274.jpg\n"
     ]
    }
   ],
   "source": [
    "print('Finding near duplicate images...')\n",
    "# Use a threshold parameter to identify two images as similar. By setting the threshold lower, \n",
    "# you will get larger clusters which have less similar images in it. Threshold 0 - 1.00\n",
    "# A threshold of 1.00 means the two images are exactly the same. Since we are finding near \n",
    "# duplicate images, we can set it at 0.99 or any number 0 < X < 1.00.\n",
    "threshold = 0.99\n",
    "near_duplicates = [image for image in processed_images if image[0] < threshold]\n",
    "\n",
    "for score, image_id1, image_id2 in near_duplicates[0:NUM_SIMILAR_IMAGES]:\n",
    "    print(\"\\nScore: {:.3f}%\".format(score * 100))\n",
    "    print(image_names[image_id1])\n",
    "    print(image_names[image_id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing orientation 98%\n",
    "#changing orientation&resolution 97%\n",
    "#changing orientation&resolution&size 96%\n",
    "#changing colors&other effect 85%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
